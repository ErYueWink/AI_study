正则化就是防止过拟合，增加模型的鲁棒性robust，鲁棒是Robust的音译，也就是强壮的意思。就像计算机软件在面临攻击、网络过载等情况下能够不死机不崩溃，这就是该软件的鲁棒性。鲁棒性调优就是让模型拥有更好的鲁棒性，也就是让模型的泛化能力和推广能力更加的强大。举以下例子：下面两个式子描述同一条直线那个更好？

![img](https://www.itbaizhan.com/wiki/imgs/wps706.jpg)

第一个更好，因为下面的公式是上面的十倍，当w越小公式的容错的能力就越好。因为把测试集带入公式中如果测试集原来是100在带入的时候发生了一些偏差，比如说变成了101，第二个模型结果就会比第一个模型结果的偏差大的多。公式中![img](https://www.itbaizhan.com/wiki/imgs/wps707.png)当x有一点错误，这个错误会通过w放大从而影响z。但是w不能太小，当w太小时正确率就无法保证，就没法做分类。想要有一定的容错率又要保证正确率就要由正则项来决定。

所以正则化（鲁棒性调优）的本质就是牺牲模型在训练集上的正确率来提高推广能力，W在数值上越小越好，这样能抵抗数值的扰动。同时为了保证模型的正确率W又不能极小。故而人们将原来的损失函数加上一个惩罚项，这里面损失函数就是原来固有的损失函数，比如回归的话通常是MSE，分类的话通常是cross entropy交叉熵，然后在加上一部分惩罚项来使得计算出来的模型W相对小一些来带来泛化能力。

