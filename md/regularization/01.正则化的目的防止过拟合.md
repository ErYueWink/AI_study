### 正则化 regularization

(1) under fit：还没有拟合到位，训练集和测试集的准确率都还没有到达最高。学的还不到位。

(2) over fit：拟合过度，训练集的准确率升高的同时，测试集的准确率反而降低。学的过度了，做过的卷子都能再次答对，考试碰到新的没见过的题就考不好。

(3) just right：过拟合前训练集和测试集准确率都达到最高时刻。学习并不需要花费很多时间，理解的很好，考试的时候可以很好的把知识举一反三。真正工作中我们是奔着过拟合的状态去调的，但是最后要的模型肯定是没有过拟合的。

![img](https://www.itbaizhan.com/wiki/imgs/wps705.png)

正则化就是防止过拟合，增加模型的鲁棒性robust，鲁棒是Robust的音译，也就是强壮的意思。就像计算机软件在面临攻击、网络过载等情况下能够不死机不崩溃，这就是该软件的鲁棒性。鲁棒性调优就是让模型拥有更好的鲁棒性，也就是让模型的泛化能力和推广能力更加的强大。举以下例子：下面两个式子描述同一条直线那个更好？

![img](https://www.itbaizhan.com/wiki/imgs/wps706.jpg)

第一个更好，因为下面的公式是上面的十倍，当w越小公式的容错的能力就越好。因为把测试集带入公式中如果测试集原来是100在带入的时候发生了一些偏差，比如说变成了101，第二个模型结果就会比第一个模型结果的偏差大的多。公式中![img](https://www.itbaizhan.com/wiki/imgs/wps707.png)当x有一点错误，这个错误会通过w放大从而影响z。但是w不能太小，当w太小时正确率就无法保证，就没法做分类。想要有一定的容错率又要保证正确率就要由正则项来决定。