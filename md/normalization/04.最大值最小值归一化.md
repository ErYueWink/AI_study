#### 归一化的本质

前面一小节我们知道了做归一化的目的是要共同富裕，而之所以梯度下降优化时不能达到步调一致的根本原因其实还是X1和X2的数量级不同。所以什么是归一化？

答案自然就出来了，就是把X1和X2的数量级给它统一，扩展一点说，如果有更多特征维度，就要把各个特征维度X1...Xn的数量级统一，来做到无量纲化。

那接下来怎么去做归一化的问题，就是怎么去把数据中的X1...Xn的数量级统一。

#### 最大值最小值归一化

min max scaling

![img](https://www.itbaizhan.com/wiki/imgs/wps680.jpg)

这里![img](https://www.itbaizhan.com/wiki/imgs/wps681.png)是对应X矩阵中第j列特征值的最小值，![img](https://www.itbaizhan.com/wiki/imgs/wps682.png)是对应X矩阵中第j列特征值的最大值，![img](https://www.itbaizhan.com/wiki/imgs/wps683.png)是X矩阵中第i行第j列的数值，![img](https://www.itbaizhan.com/wiki/imgs/wps684.png)是归一化之后的X矩阵中第i行第j列的数值。

举个例子，比如第j列的数值是[1, 2, 3, 5, 5]，![img](https://www.itbaizhan.com/wiki/imgs/wps685.png)就是1，![img](https://www.itbaizhan.com/wiki/imgs/wps686.png)就是5，那么归一化之后是[0, 0.25, 0.75, 1, 1]。如果第j列的数值是[1, 2, 3, 5, 50001]，那么归一化之后是[0, 0.00004, 0.00006, 0.0001, 1]。同学们会发现什么规律吗？

其实我们很容易发现使用最大值最小值归一化的时候，优点是一定可以把数值归一到0到1之间，缺点是如果有一个离群值，正如我们举的例子一样，会使得一个数值为1，其它数值都几乎为0，所以受离群值的影响比较大。

```
1from sklearn.preprocessing import MinMaxScaler
```

